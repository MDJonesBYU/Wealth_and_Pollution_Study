{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd11b81",
   "metadata": {},
   "source": [
    "# Data Cleaning and Manipulation\n",
    "---\n",
    "## Purpose:\n",
    "Now that we have a cursory level of understanding of the data, we want to graphically understand how the data is distributed. To do that we need to establish some functions to clean and organize the data. This codebook contains functions to clean the data and organize it, so we can conduct meaningful exploratory data analysis (EDA). \n",
    "\n",
    "### Package Installation and Versioning Requirments:\n",
    "For questions regarding python version, package installations, and other functional requirements, see the *Read Me* file contained [here](link).\n",
    "\n",
    "Now, let's begin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e340c",
   "metadata": {},
   "source": [
    "### Import Packages and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36289f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Basic_data_structure\n",
    "import numpy as np\n",
    "df_emissions, df_USDA, df_Redfin = Basic_data_structure.load_base_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb088c4d",
   "metadata": {},
   "source": [
    "### Basic Data Cleaning Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787ca1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a couple things we want to consider with the data cleaning. Ultimately we want: \n",
    "#    1. Flexibility so we can use the function(s) for univariate and multivariate analysis\n",
    "#    2. Capable of cleaning for merged and non-merged data\n",
    "#    3. Efficient considering the significant record counts.\n",
    "\n",
    "# To do this, we're going to make a few functions that allow us to group the data by county and state levels\n",
    "# and we're also going to allow for aggregation so we can see total emissions by region, or sector specific based on\n",
    "# user input. \n",
    "\n",
    "\n",
    "# let's go ahead and do this. To start we need to have some weighted avg. functions to enable us to capture a closer \n",
    "# estimate of income. \n",
    "def weighted_avg(df,series):\n",
    "    \"\"\"Generic function for calculating weighted averages based on the population. This function works for groupby\n",
    "    applications, where the variable you want to take the wegithed average of is listed in the aggregation \n",
    "    dictionary, where you would put the weighted_avg function in the value segment. The labor force column must \n",
    "    exist in the dataframe.\"\"\"\n",
    "    \n",
    "    return np.average(series, weights=df.loc[series.index, 'Civilian_labor_force_2021'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b57217",
   "metadata": {},
   "source": [
    "### Redfin Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9a25aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_begin</th>\n",
       "      <th>period_end</th>\n",
       "      <th>period_duration</th>\n",
       "      <th>region_type</th>\n",
       "      <th>region_type_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>is_seasonally_adjusted</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>sold_above_list_yoy</th>\n",
       "      <th>price_drops</th>\n",
       "      <th>price_drops_mom</th>\n",
       "      <th>price_drops_yoy</th>\n",
       "      <th>off_market_in_two_weeks</th>\n",
       "      <th>off_market_in_two_weeks_mom</th>\n",
       "      <th>off_market_in_two_weeks_yoy</th>\n",
       "      <th>parent_metro_region</th>\n",
       "      <th>parent_metro_region_metro_code</th>\n",
       "      <th>last_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/1/2017</td>\n",
       "      <td>4/30/2017</td>\n",
       "      <td>30</td>\n",
       "      <td>county</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>f</td>\n",
       "      <td>Morgan County, AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>Decatur, AL</td>\n",
       "      <td>19460.0</td>\n",
       "      <td>1/9/2022 14:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/1/2014</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>30</td>\n",
       "      <td>county</td>\n",
       "      <td>5</td>\n",
       "      <td>1457</td>\n",
       "      <td>f</td>\n",
       "      <td>Hennepin County, MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098136</td>\n",
       "      <td>0.097744</td>\n",
       "      <td>-0.121909</td>\n",
       "      <td>-0.19722</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>-0.033469</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>33460.0</td>\n",
       "      <td>1/9/2022 14:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  period_begin  period_end  period_duration region_type  region_type_id  \\\n",
       "0     4/1/2017   4/30/2017               30      county               5   \n",
       "1    12/1/2014  12/31/2014               30      county               5   \n",
       "\n",
       "   table_id is_seasonally_adjusted               region  city      state  ...  \\\n",
       "0       170                      f    Morgan County, AL   NaN    Alabama  ...   \n",
       "1      1457                      f  Hennepin County, MN   NaN  Minnesota  ...   \n",
       "\n",
       "  sold_above_list_yoy price_drops  price_drops_mom  price_drops_yoy  \\\n",
       "0           -0.069595         NaN              NaN              NaN   \n",
       "1           -0.098136    0.097744        -0.121909         -0.19722   \n",
       "\n",
       "   off_market_in_two_weeks  off_market_in_two_weeks_mom  \\\n",
       "0                 0.020833                     0.020833   \n",
       "1                 0.172414                     0.034483   \n",
       "\n",
       "   off_market_in_two_weeks_yoy  parent_metro_region  \\\n",
       "0                     0.001225          Decatur, AL   \n",
       "1                    -0.033469      Minneapolis, MN   \n",
       "\n",
       "   parent_metro_region_metro_code    last_updated  \n",
       "0                         19460.0  1/9/2022 14:29  \n",
       "1                         33460.0  1/9/2022 14:29  \n",
       "\n",
       "[2 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Redfin.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b65f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.837000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.593615e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.664403e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.300000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.631250e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.204750e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.075560e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.026250e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       median_sale_price\n",
       "count       1.837000e+03\n",
       "mean        2.593615e+05\n",
       "std         1.664403e+05\n",
       "min         9.300000e+03\n",
       "25%         1.631250e+05\n",
       "50%         2.204750e+05\n",
       "75%         3.075560e+05\n",
       "max         3.026250e+06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll start with our Redfin data. Since we only want 2021 data, we're going to apply transformations to \n",
    "# convert the period data to just 2021, so we'll slice just to capture Starting on Jan 1st of that year, and\n",
    "# ending by Dec. 31st. Now it could be interesting to explore real estate prices and fluctuations in other years\n",
    "# but that's out of scope for this project, we just want to understand houses prices in 2021 as they relate to \n",
    "# expected emissions. \n",
    "\n",
    "\n",
    "def Clean_Redfin(df, level=\"STATE\"):\n",
    "    \"\"\"this function cleans the Redfin dataset for our analysis. While there are many factors in the\n",
    "    dataset, we're just going to load those we're interested in for Wealth vs Pollution analysis. This\n",
    "    function requires the Redfin dataframe input and a specification of the level of aggregation \n",
    "    (STATE or COUNTY)\"\"\"\n",
    "\n",
    "    #Convert period data to timeseries object so we can pull from 2021 only. \n",
    "    df[['period_begin', 'period_end']] = df[['period_begin', 'period_end']].apply(pd.to_datetime)\n",
    "    \n",
    "    #Filter for sales data from 2021. We're also only going to consider residential properties. \n",
    "    df = df[(df[\"period_begin\"].dt.year==2021) & (df[\"property_type\"]==\"All Residential\") & \n",
    "            (df[\"region_type\"]==\"county\")].reset_index() \n",
    "    \n",
    "    #Remove nan sale entries: \n",
    "    df = df.dropna(subset=\"median_sale_price\")\n",
    "    \n",
    "    if level == \"STATE\":\n",
    "        #Take median sale prices at the state level\n",
    "        df = df.groupby(\"state\").agg(\n",
    "            {'median_sale_price': \"median\",\"state_code\": \"first\"}).reset_index() \n",
    "        \n",
    "        #also let's exclude DC. It's not a state.\n",
    "        df = df[df[\"state\"] != \"Columbia\"]        \n",
    "\n",
    "    elif level == \"COUNTY\":\n",
    "        #Take median sale prices at the county level\n",
    "        df = df.groupby(\"region\").agg(\n",
    "            {'median_sale_price': \"median\", \"state\": \"first\", \"state_code\": \"first\"}).reset_index() \n",
    "    else: \n",
    "        raise ValueError(\"Level must be entered as 'STATE' or 'COUNTY'.\")\n",
    "        \n",
    "    # Next let's round the sale prices. Generally the prices have 5 significant digits, so we'll reduce broadly\n",
    "    # We're taking the log of the sale price (abs in case quit-claims), rounding to the nearest integer using floor\n",
    "    # and converting the float to an int. 5 is our sig digits, so N-int(...) gets use num digits to round by. \n",
    "    # then as a lambda function, we're rounding each element (x = row entry) by N-int digits of the sales column\n",
    "    N=5\n",
    "    df['median_sale_price'] = df['median_sale_price'].apply(lambda x: round(x, N - int(np.floor(np.log10(abs(x))))))\n",
    "\n",
    "    return(df)\n",
    "\n",
    "df_Redfin_Clean = Clean_Redfin(df_Redfin, \"COUNTY\")\n",
    "df_Redfin_Clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9edfe6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we see we have 46 states with sale price data, not too bad. And we can see the home prices skew\n",
    "# higher by about 20-25k. Not too bad. Let's now clean the USDA dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ba426",
   "metadata": {},
   "source": [
    "### USDA Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dd2aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_Code</th>\n",
       "      <th>State</th>\n",
       "      <th>Area_Name</th>\n",
       "      <th>Rural_Urban_Continuum_Code_2013</th>\n",
       "      <th>Urban_Influence_Code_2013</th>\n",
       "      <th>Metro_2013</th>\n",
       "      <th>Civilian_labor_force_2000</th>\n",
       "      <th>Employed_2000</th>\n",
       "      <th>Unemployed_2000</th>\n",
       "      <th>Unemployment_rate_2000</th>\n",
       "      <th>...</th>\n",
       "      <th>Civilian_labor_force_2021</th>\n",
       "      <th>Employed_2021</th>\n",
       "      <th>Unemployed_2021</th>\n",
       "      <th>Unemployment_rate_2021</th>\n",
       "      <th>Civilian_labor_force_2022</th>\n",
       "      <th>Employed_2022</th>\n",
       "      <th>Unemployed_2022</th>\n",
       "      <th>Unemployment_rate_2022</th>\n",
       "      <th>Median_Household_Income_2021</th>\n",
       "      <th>Med_HH_Income_Percent_of_State_Total_2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142601576.0</td>\n",
       "      <td>136904853.0</td>\n",
       "      <td>5696723.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>162229903.0</td>\n",
       "      <td>153544980.0</td>\n",
       "      <td>8684923.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>164781642.0</td>\n",
       "      <td>158766998.0</td>\n",
       "      <td>6014644.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>69717.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2147173.0</td>\n",
       "      <td>2047731.0</td>\n",
       "      <td>99442.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2259349.0</td>\n",
       "      <td>2183330.0</td>\n",
       "      <td>76019.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2286028.0</td>\n",
       "      <td>2226670.0</td>\n",
       "      <td>59358.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>53990.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS_Code State      Area_Name  Rural_Urban_Continuum_Code_2013  \\\n",
       "0          0    US  United States                              NaN   \n",
       "1       1000    AL        Alabama                              NaN   \n",
       "\n",
       "   Urban_Influence_Code_2013  Metro_2013  Civilian_labor_force_2000  \\\n",
       "0                        NaN         NaN                142601576.0   \n",
       "1                        NaN         NaN                  2147173.0   \n",
       "\n",
       "   Employed_2000  Unemployed_2000  Unemployment_rate_2000  ...  \\\n",
       "0    136904853.0        5696723.0                     4.0  ...   \n",
       "1      2047731.0          99442.0                     4.6  ...   \n",
       "\n",
       "   Civilian_labor_force_2021  Employed_2021  Unemployed_2021  \\\n",
       "0                162229903.0    153544980.0        8684923.0   \n",
       "1                  2259349.0      2183330.0          76019.0   \n",
       "\n",
       "   Unemployment_rate_2021  Civilian_labor_force_2022  Employed_2022  \\\n",
       "0                     5.4                164781642.0    158766998.0   \n",
       "1                     3.4                  2286028.0      2226670.0   \n",
       "\n",
       "   Unemployed_2022  Unemployment_rate_2022  Median_Household_Income_2021  \\\n",
       "0        6014644.0                     3.7                       69717.0   \n",
       "1          59358.0                     2.6                       53990.0   \n",
       "\n",
       "   Med_HH_Income_Percent_of_State_Total_2021  \n",
       "0                                        NaN  \n",
       "1                                      100.0  \n",
       "\n",
       "[2 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_USDA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ea35d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Civilian_labor_force_2021</th>\n",
       "      <th>Median_Household_Income_2021</th>\n",
       "      <th>Unemployment_rate_2021</th>\n",
       "      <th>Rural_Urban_Continuum_Code_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.191000e+03</td>\n",
       "      <td>3191.000000</td>\n",
       "      <td>3191.000000</td>\n",
       "      <td>3139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.014428e+05</td>\n",
       "      <td>59087.613914</td>\n",
       "      <td>4.651739</td>\n",
       "      <td>5.009239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.183808e+05</td>\n",
       "      <td>15250.869635</td>\n",
       "      <td>1.723035</td>\n",
       "      <td>2.707585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.860000e+02</td>\n",
       "      <td>25653.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.886500e+03</td>\n",
       "      <td>49154.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.190500e+04</td>\n",
       "      <td>56764.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.382550e+04</td>\n",
       "      <td>65889.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.897338e+07</td>\n",
       "      <td>153716.000000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Civilian_labor_force_2021  Median_Household_Income_2021  \\\n",
       "count               3.191000e+03                   3191.000000   \n",
       "mean                1.014428e+05                  59087.613914   \n",
       "std                 6.183808e+05                  15250.869635   \n",
       "min                 1.860000e+02                  25653.000000   \n",
       "25%                 4.886500e+03                  49154.500000   \n",
       "50%                 1.190500e+04                  56764.000000   \n",
       "75%                 3.382550e+04                  65889.500000   \n",
       "max                 1.897338e+07                 153716.000000   \n",
       "\n",
       "       Unemployment_rate_2021  Rural_Urban_Continuum_Code_2013  \n",
       "count             3191.000000                      3139.000000  \n",
       "mean                 4.651739                         5.009239  \n",
       "std                  1.723035                         2.707585  \n",
       "min                  0.900000                         1.000000  \n",
       "25%                  3.500000                         2.000000  \n",
       "50%                  4.400000                         6.000000  \n",
       "75%                  5.500000                         7.000000  \n",
       "max                 19.500000                         9.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Clean_USDA(df, level=\"STATE\"):\n",
    "    \"\"\"This function cleans the USDA dataset and performs aggregation  based on the level (COUNTY or STATE)\n",
    "    based on user declarations.\"\"\"\n",
    "    \n",
    "    # First, let's down-select to the columns we're interested in. Recall from the last notebook, that we \n",
    "    # will keep the 2013 rural/urban rankings as a coarse way to evaluate emission differences based on\n",
    "    # population density. \n",
    "    df = df[[\"State\", \"Area_Name\", 'Civilian_labor_force_2021', \"Rural_Urban_Continuum_Code_2013\",\n",
    "             \"Median_Household_Income_2021\", \"Unemployment_rate_2021\", \"FIPS_Code\",]].astype({\"FIPS_Code\": str})\n",
    "    \n",
    "    #remove areas with nan for income, unemployment, or labor force: \n",
    "    df = df.dropna(subset =[\"Unemployment_rate_2021\", \"Median_Household_Income_2021\", \"Civilian_labor_force_2021\"])\n",
    "    \n",
    "    # We want to set the FIPS code to string type. The reason will be apparent when we merge this\n",
    "    # data with our emission data. The zfill, ensures that each string is left padded with zeros to make each\n",
    "    # 5 character length. In case a code (003 becomes clipped as 3)\n",
    "    df[\"FIPS_Code\"] = df[\"FIPS_Code\"].astype(str).str.zfill(5)\n",
    "     \n",
    "    # Filter to the columns of interest. From this dataset we want the income, unemployment, labor force size, \n",
    "    # rural/urban designation, and the FIPs. Brining in Area_name is not necessary, but helpful for reading\n",
    "    # in our initial exploration\n",
    "    cols = [\"FIPS_Code\", \"Area_Name\", \"State\", \"Civilian_labor_force_2021\", \n",
    "            \"Median_Household_Income_2021\", \"Unemployment_rate_2021\", \"Rural_Urban_Continuum_Code_2013\"]\n",
    "    df = df[cols]\n",
    "    \n",
    "    # U.S. Territories are out of scope for this project, so we're removing them. The ~ is a negation operator\n",
    "    # basically saying give me all the records where the states are not in the exclusion list. \n",
    "    exclusion_list = [\"PR\", \"DC\", \"US\"]\n",
    "    df = df[~df[\"State\"].isin(exclusion_list)].reset_index(drop=True)\n",
    "    \n",
    "    #We'll add a column for the state fips which will be usefull later\n",
    "    df[\"State_FIPS\"] = df['FIPS_Code'].apply(lambda x: x[:2])\n",
    "    \n",
    "    # similar to the Redfin data, we're going to group this by level specification. Since we want to weight the \n",
    "    if level==\"STATE\":\n",
    "        agg_dict = { \"FIPS_Code\": \"first\", \"Civilian_labor_force_2021\": \"sum\", \n",
    "                    \"Median_Household_Income_2021\": lambda x: weighted_avg(df, x),\n",
    "                    \"Unemployment_rate_2021\":lambda x: weighted_avg(df, x), \"State_FIPS\": \"first\"}\n",
    "\n",
    "        df = df.groupby(\"State\").agg(agg_dict).reset_index()\n",
    "        \n",
    "        return(df)\n",
    "    else: \n",
    "        return(df)\n",
    "df_USDA_Clean = Clean_USDA(df_USDA, \"COUNTY\")\n",
    "df_USDA_Clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c8ecd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, we see that we have all 50 states accounted for in our dataset, and the numbers look reasonable. \n",
    "# The Median income, averaged across all 50 states is roughly 70k, which is pretty close to estimates from\n",
    "# Census.Gov for 2021. Labor force size is going to be right skewed (at state level, and Unemployment seems\n",
    "# to fall in line with the median. When we plot this we'll understand it better). \n",
    "\n",
    "#Let's now clean the Emission Data. This is going to be much more involved than the other datasources. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a5de6",
   "metadata": {},
   "source": [
    "### EPA Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca684232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE FIPS</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>COUNTY FIPS</th>\n",
       "      <th>POLLUTANT</th>\n",
       "      <th>POLLUTANT TYPE</th>\n",
       "      <th>EMISSIONS</th>\n",
       "      <th>UNIT OF MEASURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OR</td>\n",
       "      <td>41</td>\n",
       "      <td>Clackamas</td>\n",
       "      <td>Fires - Wildfires</td>\n",
       "      <td>005</td>\n",
       "      <td>Carbon Monoxide</td>\n",
       "      <td>CAP</td>\n",
       "      <td>1777086</td>\n",
       "      <td>TON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OR</td>\n",
       "      <td>41</td>\n",
       "      <td>Marion</td>\n",
       "      <td>Fires - Wildfires</td>\n",
       "      <td>047</td>\n",
       "      <td>Carbon Monoxide</td>\n",
       "      <td>CAP</td>\n",
       "      <td>1551703</td>\n",
       "      <td>TON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATE STATE FIPS     COUNTY             SECTOR COUNTY FIPS        POLLUTANT  \\\n",
       "0    OR         41  Clackamas  Fires - Wildfires         005  Carbon Monoxide   \n",
       "1    OR         41     Marion  Fires - Wildfires         047  Carbon Monoxide   \n",
       "\n",
       "  POLLUTANT TYPE  EMISSIONS UNIT OF MEASURE  \n",
       "0            CAP    1777086             TON  \n",
       "1            CAP    1551703             TON  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the EPA dataset has emissions by sectors, and we might want to probe sectoral as well as regional differences\n",
    "# We're going to first create some background functions to help us deal with condensing the sectors into primary groups \n",
    "# first going to create a function to allow # us to condense the dataframe to Major sectors like (Mobile, Industrial,\n",
    "# fuel combustion, etc.)\n",
    "df_emissions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ca1cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_emissions_by_major_sectors(df, level, options_dict):\n",
    "    \"\"\"This function takes in the emissions dataframe, a specified grouping level, an input dictionary, which \n",
    "    will contain keys that are the major sectors we'd like to consider and a list of string values for each \n",
    "    major sector key. \"\"\"\n",
    "    \n",
    "    df_list = []\n",
    "    # We're going to do this by calling the K-V pairs using dict.items(). sector is our key, and options is our \n",
    "    # value list. We'll be iterating using a for loop. \n",
    "    \n",
    "    for sector, options in options_dict.items():\n",
    "        #make a subset dataframe where the sectors are only those specified in the current K-V pair. \n",
    "        filtered_df = df[df['SECTOR'].isin(options)]\n",
    "        \n",
    "        # add the dataframe to a list, while adding a new column for our Primary sectors (the keys in our options \n",
    "        # dictionary)\n",
    "        df_list.append(filtered_df.assign(Major_Sector=sector))\n",
    "    \n",
    "    # Once done looping, concat the dataframes. \n",
    "    agg_df = pd.concat(df_list)\n",
    "    \n",
    "    # Next we'll use groupby method to group the emissions based on the major sector and the Count/State FIPS \n",
    "    # Depending on the level specified. \n",
    "    if level == \"COUNTY\": \n",
    "        grouped_df = agg_df.groupby([\"COUNTY FIPS\", \"Major_Sector\"]).agg(\n",
    "            {'EMISSIONS': \"sum\", \"STATE\": \"first\", \"STATE FIPS\": \"first\", \"COUNTY\": \"first\"}).reset_index()\n",
    "    elif level == \"STATE\":\n",
    "        grouped_df = agg_df.groupby([\"STATE FIPS\", \"Major_Sector\"]).agg(\n",
    "                    {'EMISSIONS': \"sum\", \"STATE\": \"first\"}).reset_index()\n",
    "    else: \n",
    "        raise ValueError(\"You must specify 'COUNTY' or 'STATE' for the level.\")\n",
    "    return grouped_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd87026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next let's make our function to supply the options_dict to our sector-grouping function above.\n",
    "def create_options_dict(input_set):\n",
    "    \"\"\"This function creates the options_dict that will be supplied when group_emissions_by_major_sector\n",
    "    is called. This function required the input_dict of options, which will be the set of all sectors provided. \"\"\"\n",
    "\n",
    "    # We want just 6 main categories, but there's not a broadly applicable way to directly do this. So, we're \n",
    "    # going to map those connections to the primary sector here.  \n",
    "    category_mapping = {\n",
    "        'Solvent': 'Industrial Processes',\n",
    "        'Gas Stations': 'Commercial',\n",
    "        'Agriculture': 'Industrial Processes',\n",
    "        'Commercial Cooking': 'Commercial',\n",
    "        'Bulk Gasoline Terminals': 'Industrial Processes',\n",
    "        'Waste Disposal': 'Industrial Processes',\n",
    "        'Dust': 'Industrial Processes',\n",
    "        'Biogenics': \"Miscellaneous Non-Industrial NEC\"\n",
    "    }\n",
    "\n",
    "    # Now we're going to create our new dictionary containing our primary sectors, and the secondary level(s) as a \n",
    "    # value list of string entries. \n",
    "    options_dict = {}\n",
    "    for option in input_set:\n",
    "        \n",
    "        # Identify Primary Sectors using the split method on ' - ', taking the first item from the resulting split list \n",
    "        category = option.split(' - ')[0]\n",
    "        \n",
    "        # use .get method to see if our primary sector is in our category_mapping dictionary. use category 2x to check\n",
    "        # both the keys and the values\n",
    "        mapped_category = category_mapping.get(category, category)\n",
    "        \n",
    "        #if the primary sector is not already in our new dictionary, we're going to add it. \n",
    "        if mapped_category not in options_dict:\n",
    "            options_dict[mapped_category] = []\n",
    "        \n",
    "        # And for each element in the input_set we're going to add it as a value corresponding to the appropriate \n",
    "        # primary sectory key (mapped category)\n",
    "        options_dict[mapped_category].append(option)\n",
    "    options_dict\n",
    "    return(options_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7dd6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now let's setup our cleaning function so that depending on the level selected, sector desired, and emission \n",
    "# contributions, we are able to get the output dataframe we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bbf0988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_EPA(df, level=\"STATE\", emission_contributor=\"residential\", agg=True):\n",
    "    \"\"\"This function cleans the EPA Emission dataset and performs aggregation  based on the level (county or state), \n",
    "    sector inclusion/exclusion, and emission contributors (residential, industrial, etc). At the end, this function\n",
    "    returns a dataframe ready for user analysis. Contributor options are 'residential', 'industrial', 'commercial',\n",
    "    'by sector', or 'all'. \"\"\"\n",
    "    \n",
    "    #Add a column for unity County, State FIPS ID: \n",
    "    if level==\"COUNTY\":\n",
    "        df[\"FIPS\"] = df[\"STATE FIPS\"] + df[\"COUNTY FIPS\"]\n",
    "\n",
    "    \n",
    "    #We will Filter based on emission_contributor: \n",
    "    emission_sectors = set(df_emissions[\"SECTOR\"])\n",
    "    \n",
    "    if emission_contributor == \"by sector\": \n",
    "        #get the options dictionary \n",
    "        options_dict = create_options_dict(emission_sectors)\n",
    "        #run the grouping function for the sectors\n",
    "        df = group_emissions_by_major_sectors(df, level, options_dict)\n",
    "    \n",
    "    elif emission_contributor in [\"residential\", \"industrial\", \"commercial\"]:\n",
    "        #Get dictionary of strings to search for each string entry in our sector list. \n",
    "        options_dict = {\n",
    "            \"residential\": [\"Residential\", \"Light Duty\"],\n",
    "            \"commercial\": [\"Comm/Institutional\", \"Commercial\", \"Dry Cleaning\", \"Graphic Arts\", \"Gas Stations\"],\n",
    "            \"industrial\": [\"Industrial\", \"Bulk\", \"Agriculture\", \"Waste\", \"Degreasing\", \"Electric Generation\", \n",
    "                           \"Locomotive\", \"Aircraft\"]}\n",
    "        \n",
    "        # Create a list of desired sectors via list comprehension. We do this by iterating through each entry in \n",
    "        # emission_sectors, and checking if any of the string entries from the value list corresponding to our \n",
    "        # sector key are in the list by using the .get method on our options dict.  \n",
    "        desired_sectors = [val for val in emission_sectors if any(option in val for option in options_dict.get(\n",
    "            emission_contributor, []))]\n",
    "        #reduce the dataframe to only consider those particular emissions contributors: \n",
    "        df = df[df[\"SECTOR\"].isin(desired_sectors)]\n",
    "        \n",
    "    elif emission_contributor != \"all\":\n",
    "        raise ValueError(\"\"\"You must specify one of the following options for sector:\\\n",
    "        'residential', 'industrial', 'commercial','by sector', or 'all' \"\"\")\n",
    "    \n",
    "    # Now group based on level and aggregation specified. \n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    if level == \"STATE\" and agg == True: \n",
    "        df = df.groupby(\"STATE FIPS\").agg(\n",
    "        {'EMISSIONS': \"sum\",\"STATE\": \"first\"}).reset_index() \n",
    "            \n",
    "    elif level == \"COUNTY\" and agg == True: \n",
    "        df = df.groupby(\"FIPS\").agg(\n",
    "        {'EMISSIONS': \"sum\",\"STATE FIPS\": \"first\", \"STATE\": \"first\", \n",
    "         \"COUNTY\": \"first\", \"COUNTY FIPS\": \"first\"}).reset_index()\n",
    "        \n",
    "    elif level == \"STATE\" and agg == False: \n",
    "        try: \n",
    "            df = df.groupby([\"Major_Sector\", \"STATE FIPS\"]).agg(\n",
    "                {'EMISSIONS': \"sum\", \"STATE\": \"first\"}).reset_index()         \n",
    "        except: \n",
    "            df = df.groupby([\"SECTOR\", \"STATE FIPS\"]).agg(\n",
    "                {'EMISSIONS': \"sum\", \"STATE\": \"first\"}).reset_index()        \n",
    "\n",
    "    #We're also going to create a FIPS column containing the unique code associated with each county. \n",
    "    output_df = df.copy(deep=True)\n",
    "\n",
    "    #if level is county, we'll add in the FIPS code: \n",
    "    if level == \"COUNTY\": \n",
    "        output_df[\"FIPS\"] = df['STATE FIPS'].astype(str).str.zfill(2) + df['COUNTY FIPS'].astype(str).str.zfill(3)\n",
    "        output_df[\"Region\"] = output_df[\"COUNTY\"] + ' County, ' + output_df[\"STATE\"]\n",
    "    #Finally, let's remove non-states\n",
    "    exclusion_list = [\"TR\", \"DM\", \"PR\", \"VI\", \"DC\"]\n",
    "    output_df = output_df[~output_df[\"STATE\"].isin(exclusion_list)]\n",
    "    \n",
    "    #and return the dataframe: \n",
    "    return(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23d22f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMISSIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3142.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5195.042648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9834.691370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1033.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2307.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5269.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191813.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           EMISSIONS\n",
       "count    3142.000000\n",
       "mean     5195.042648\n",
       "std      9834.691370\n",
       "min         1.000000\n",
       "25%      1033.250000\n",
       "50%      2307.500000\n",
       "75%      5269.250000\n",
       "max    191813.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emissions_Clean = Clean_EPA(df_emissions, \"COUNTY\", \"residential\", agg=True)\n",
    "df_emissions_Clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a60e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have established functions for cleaning our EPA, Redfin, and USDA datasets, and preparing them for univariate\n",
    "# analysis. We'll go ahead and finish our data cleaning and manipulation work by establishing a function for merging\n",
    "# the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a791a49",
   "metadata": {},
   "source": [
    "### Merging the Cleaned data together: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4f62953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_df (df_emission, df_USDA, df_Redfin, level):\n",
    "    \"\"\"This function will merge the data together into a singular dataframe based on the loaded dataframes from\n",
    "    the EPA, USDA, and Redfin, as well as the level at which merging occurs. Level specification is important\n",
    "    since it influences how we will merge the data.\"\"\"\n",
    "    \n",
    "    \n",
    "    if level == \"STATE\": \n",
    "        #Provide list of merged columns we'll want\n",
    "        keep_cols = [\"STATE\", \"STATE FIPS\", \"EMISSIONS\", \"Civilian_labor_force_2021\", \n",
    "                         \"Median_Household_Income_2021\", \"Unemployment_rate_2021\", \"median_sale_price\",\n",
    "                        \"state\"]\n",
    "        if \"Major_Sector\" in list(df_emission.columns): \n",
    "            keep_cols.append(\"Major_Sector\")\n",
    "\n",
    "        merged_df = pd.merge(df_emission, df_USDA, left_on='STATE FIPS', right_on=\"State_FIPS\", \n",
    "                             how='inner').reset_index()\n",
    "        merged_df = pd.merge(merged_df, df_Redfin, left_on='State', right_on=\"state_code\", how='inner').reset_index()\n",
    "        merged_df = merged_df[keep_cols]\n",
    "\n",
    "    elif level == \"COUNTY\":\n",
    "        #Provide list of merged columns we'll want\n",
    "        keep_cols = [\"STATE\", \"STATE FIPS\", \"COUNTY FIPS\", \"COUNTY\", \"Rural_Urban_Continuum_Code_2013\", \n",
    "                     \"EMISSIONS\", \"Civilian_labor_force_2021\",\"Median_Household_Income_2021\", \n",
    "                     \"Unemployment_rate_2021\", \"median_sale_price\"]\n",
    "        if \"Major_Sector\" in df_emission.columns: \n",
    "            keep_cols.append(\"Major_Sector\")   \n",
    "\n",
    "        merged_df = pd.merge(df_emission, df_USDA, left_on='FIPS', right_on=\"FIPS_Code\", \n",
    "                             how='inner').reset_index()\n",
    "        merged_df = pd.merge(merged_df, df_Redfin, left_on='Region', right_on=\"region\", how='inner').reset_index()\n",
    "        merged_df = merged_df[keep_cols]        \n",
    "\n",
    "    return(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e03181ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its here\n"
     ]
    }
   ],
   "source": [
    "#In the future we'll keep the code block below for simple calls to get our County and State dataframes for analysis.  \n",
    "df_Redfin_County = Clean_Redfin(df_Redfin, \"COUNTY\")\n",
    "df_USDA_County = Clean_USDA(df_USDA, \"COUNTY\")\n",
    "df_emissions_County = Clean_EPA(df_emissions, \"COUNTY\", \"by sector\", agg=False)\n",
    "\n",
    "\n",
    "df_Redfin_State = Clean_Redfin(df_Redfin, \"STATE\")\n",
    "df_USDA_State = Clean_USDA(df_USDA, \"STATE\")\n",
    "df_emissions_State = Clean_EPA(df_emissions, \"STATE\", \"by sector\", agg=False)\n",
    "\n",
    "\n",
    "df_merged_state = get_merge_df(df_emissions_State,df_USDA_State,df_Redfin_State, level=\"STATE\")\n",
    "df_merged_cty = get_merge_df(df_emissions_County,df_USDA_County,df_Redfin_County, level=\"COUNTY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dacee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excellent, now we have functions that enable us to clean and filter the data with a lot of flexibility. If we want to \n",
    "# check pollution vs. wealth differences at state / county levels we can, and we can even drill down to whether we \n",
    "# want to include sectoral differences. \n",
    "\n",
    "# Obviously this flexibility comes at the cost of making a function which is less readible, and harder to immediately \n",
    "# understand. However, we chose this to maximize flexibility for future analysis so that only minor data manipulation \n",
    "# is needed down the road."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57db8ae9",
   "metadata": {},
   "source": [
    "### End of Notebook\n",
    "\n",
    "Next notebook: Univariate EDA \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b8d7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE FIPS</th>\n",
       "      <th>COUNTY FIPS</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>Rural_Urban_Continuum_Code_2013</th>\n",
       "      <th>EMISSIONS</th>\n",
       "      <th>Civilian_labor_force_2021</th>\n",
       "      <th>Median_Household_Income_2021</th>\n",
       "      <th>Unemployment_rate_2021</th>\n",
       "      <th>median_sale_price</th>\n",
       "      <th>Major_Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT</td>\n",
       "      <td>09</td>\n",
       "      <td>001</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>465562.0</td>\n",
       "      <td>100703.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>484500.0</td>\n",
       "      <td>Commercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT</td>\n",
       "      <td>09</td>\n",
       "      <td>001</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>2.0</td>\n",
       "      <td>562700</td>\n",
       "      <td>465562.0</td>\n",
       "      <td>100703.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>484500.0</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NY</td>\n",
       "      <td>36</td>\n",
       "      <td>001</td>\n",
       "      <td>Albany</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38343</td>\n",
       "      <td>158446.0</td>\n",
       "      <td>74512.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>260500.0</td>\n",
       "      <td>Industrial Processes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HI</td>\n",
       "      <td>15</td>\n",
       "      <td>001</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63850</td>\n",
       "      <td>93899.0</td>\n",
       "      <td>67896.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>487250.0</td>\n",
       "      <td>Miscellaneous Non-Industrial NEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NV</td>\n",
       "      <td>32</td>\n",
       "      <td>003</td>\n",
       "      <td>Clark</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2762</td>\n",
       "      <td>1097343.0</td>\n",
       "      <td>63735.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>370500.0</td>\n",
       "      <td>Commercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>507</td>\n",
       "      <td>Zavala</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1520</td>\n",
       "      <td>3286.0</td>\n",
       "      <td>35046.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>63500.0</td>\n",
       "      <td>Fires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>507</td>\n",
       "      <td>Zavala</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3286.0</td>\n",
       "      <td>35046.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>63500.0</td>\n",
       "      <td>Fuel Comb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>507</td>\n",
       "      <td>Zavala</td>\n",
       "      <td>7.0</td>\n",
       "      <td>784</td>\n",
       "      <td>3286.0</td>\n",
       "      <td>35046.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>63500.0</td>\n",
       "      <td>Industrial Processes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>507</td>\n",
       "      <td>Zavala</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1568</td>\n",
       "      <td>3286.0</td>\n",
       "      <td>35046.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>63500.0</td>\n",
       "      <td>Miscellaneous Non-Industrial NEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>507</td>\n",
       "      <td>Zavala</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1026</td>\n",
       "      <td>3286.0</td>\n",
       "      <td>35046.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>63500.0</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1141 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATE STATE FIPS COUNTY FIPS     COUNTY  Rural_Urban_Continuum_Code_2013  \\\n",
       "0       CT         09         001  Fairfield                              2.0   \n",
       "1       CT         09         001  Fairfield                              2.0   \n",
       "2       NY         36         001     Albany                              2.0   \n",
       "3       HI         15         001     Hawaii                              5.0   \n",
       "4       NV         32         003      Clark                              1.0   \n",
       "...    ...        ...         ...        ...                              ...   \n",
       "1136    TX         48         507     Zavala                              7.0   \n",
       "1137    TX         48         507     Zavala                              7.0   \n",
       "1138    TX         48         507     Zavala                              7.0   \n",
       "1139    TX         48         507     Zavala                              7.0   \n",
       "1140    TX         48         507     Zavala                              7.0   \n",
       "\n",
       "      EMISSIONS  Civilian_labor_force_2021  Median_Household_Income_2021  \\\n",
       "0          1920                   465562.0                      100703.0   \n",
       "1        562700                   465562.0                      100703.0   \n",
       "2         38343                   158446.0                       74512.0   \n",
       "3         63850                    93899.0                       67896.0   \n",
       "4          2762                  1097343.0                       63735.0   \n",
       "...         ...                        ...                           ...   \n",
       "1136       1520                     3286.0                       35046.0   \n",
       "1137         15                     3286.0                       35046.0   \n",
       "1138        784                     3286.0                       35046.0   \n",
       "1139       1568                     3286.0                       35046.0   \n",
       "1140       1026                     3286.0                       35046.0   \n",
       "\n",
       "      Unemployment_rate_2021  median_sale_price  \\\n",
       "0                        6.1           484500.0   \n",
       "1                        6.1           484500.0   \n",
       "2                        4.4           260500.0   \n",
       "3                        5.8           487250.0   \n",
       "4                        7.9           370500.0   \n",
       "...                      ...                ...   \n",
       "1136                    12.4            63500.0   \n",
       "1137                    12.4            63500.0   \n",
       "1138                    12.4            63500.0   \n",
       "1139                    12.4            63500.0   \n",
       "1140                    12.4            63500.0   \n",
       "\n",
       "                          Major_Sector  \n",
       "0                           Commercial  \n",
       "1                               Mobile  \n",
       "2                 Industrial Processes  \n",
       "3     Miscellaneous Non-Industrial NEC  \n",
       "4                           Commercial  \n",
       "...                                ...  \n",
       "1136                             Fires  \n",
       "1137                         Fuel Comb  \n",
       "1138              Industrial Processes  \n",
       "1139  Miscellaneous Non-Industrial NEC  \n",
       "1140                            Mobile  \n",
       "\n",
       "[1141 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_cty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ab288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
